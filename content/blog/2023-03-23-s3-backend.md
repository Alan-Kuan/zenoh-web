---
title: "Zenoh Storage Gets a Boost: Empowering Storage with S3 Integration"
date: 2023-03-23
menu: "blog"
weight: 20230321
description: "23 March 2023 -- Paris"
draft: false
---

# Zenoh Storage Gets a Boost: Empowering Storage with S3 Integration

As we happily announced on our recent blog post [Zenoh Charmander is coming to town](https://zenoh.io/blog/2023-01-10-zenoh-charmander/), Zenoh has now enhanced backend storage capabilities with the new AmazonS3/MinIO backend implementation performed for release 0.7.0-rc.

This was a requested feature that originated within [our community on Discord](https://discord.gg/2GJ958VuHs) (which btw feel free to join!) and soon made its way into the [roadmap](https://github.com/eclipse-zenoh/roadmap).

The S3 backend can be installed by downloading the package from ​​[https://download.eclipse.org/zenoh/zenoh-backend-s3/latest/](https://download.eclipse.org/zenoh/zenoh-backend-s3/latest/). The source code can be found in our eclipse-zenoh repository: [https://github.com/eclipse-zenoh/zenoh-backend-s3](https://github.com/eclipse-zenoh/zenoh-backend-s3)

Inside you will find a README with detailed instructions on how to set up this backend for both Amazon S3 and MinIO.

# Zenoh Backends

You may ask yourself “what is a backend?”. Well, in Zenoh a backend is a storage technology allowing to store the key/values publications made via Zenoh and return them on queries. Different storage technologies allow storing key/values based on different use cases.

At the moment we have three backend systems:

- [InfluxDB](https://www.influxdata.com/): a time series data platform userful for developers to build IoT, analytics and cloud applications
  - Repository: [https://github.com/eclipse-zenoh/zenoh-backend-influxdb](http://eclipse-zenoh/zenoh-backend-influxdb)
- [RocksDB](http://rocksdb.org/): a high-performance persistent key-value store for fast storage environments
  - Repository: https://github.com/eclipse-zenoh/zenoh-backend-rocksdb
- FileSystem: this backend relies on the host's file system to implement the storages.
  - Repository: [https://github.com/eclipse-zenoh/zenoh-backend-filesystem](https://github.com/eclipse-zenoh/zenoh-backend-filesystem)

AmazonS3 joins this list with the capability of storing the data on a cloud storage service.

It will boost our storage capabilities, especially when it comes to object oriented storage. So far the only way to work with object storages was using the FileSystem backend which was designed to be a simple storage option constrained into the host’s filesystem. It is a backend that also lacks many of the mechanisms a cloud storage provides regarding security, data availability and performance, and is not very scalable either.

Our users needed the possibility to interact with an object storage technology that could easily be set up on the cloud, that would already provide performance, security and data availability and that could be scalable. Amazon S3 reunited all of these conditions and was immediately proposed, as up to today it’s been a proven technology with a broad adoption in the systems industry.

# Features

## S3 storage

[Amazon S3](https://aws.amazon.com/s3/) (which stands for Simple Storage Service) provides object storage capabilities through Amazon Web Services, offering “industry-leading scalability, data availability, security, and performance”.

This backend allows us to:

- store values as files/objects in an S3 bucket
- create a bucket
- reuse an existing bucket
- put values on the storage, that is to create or update a file in the storage with the value specified, under the path provided by the key expression
- query values / files with:
  - concrete key expressions
  - key expressions containing wild cards (`\*` and `\*\*`) (which will return the values of the files whose path match the key expression)
- delete files
- delete the storage

![S3 storage backend](../../img/20220922-blog-zenoh-charmander/s3.png)

## Compatibility with MinIO

[MinIO](http://min.io) is an open source multi-cloud object storage that offers high-performance and is an S3 compatible object storage. We developed the backend in order for you to be able to either choose AmazonS3 or MinIO depending on your use cases. There may be many factors for you to decide on one over the other. One to consider is the amount of interactions with the storage, as with Zenoh, you can receive thousands of requests to put or retrieve data from a storage, which can have an impact on the pricing of your storage in case of using Amazon S3.

## TLS support

AmazonS3 provides HTTPS support per se, but if you set up your own S3 instances using MinIO, you’ll probably want to secure the connection using TLS. For that you need to specify the certificates that will allow you to authenticate your servers. That certificate from the certificate authority can be specified in the configuration file.

# Configuration

An example configuration file can be found in [our repository](https://github.com/eclipse-zenoh/zenoh-backend-s3/blob/main/zenoh.json5). In it you will see we have parameters for ‘volumes’ and ‘storages’.

In our conception of what an S3 storage is, each storage is associated with an S3 bucket, while a volume is associated with a server. A volume can be associated with many storages, which means that all the s3 buckets are going to be stored on the same server.

The volume configuration required is limited to specifying where the server is going to be located (if you are using Amazon S3 you need to specify only the region, while when using MinIO you need to provide an url) and eventually the TLS certificate path. All the storages associated with it will share the same configuration.

Within the storage configuration, we specify the key expression, the name of the bucket, the credentials needed to access it, some policies related to the creation of the storage and its read-write permissions, etc… More detail is provided in the example config file.

# Considerations

Keep in mind that this S3 backend is still a work in progress and some extra work on it is to be expected.

There are a couple things to consider when using this backend at this stage, some related to how MinIO and AmazonS3 work and some related to the status of the development of this backend.

## Same name files and directories

Regarding the differences between MinIO and AmazonS3, MinIO is “S3 compatible”, which doesn’t mean it works identically.

One difference we noted during the development emerged from the question: what if we put a value under the key ‘a/b’ and later another one under `a/b/c`. With Zenoh one may expect this to be possible; Zenoh allows you to publish a value under `a/b/c` or under `a/b`, receivers subscribed to `a/\*\*` for instance should be able to receive both events, independently if the listener is a storage or not.

So how does the system behave when dealing with this situation?

```
└── a
    ├── b
    │   └── c
    └── b
```

Performing a publication under `a/b` and later under `a/b/c` (or inversely) means we’ll have a directory with the same name as a file under the same location, under `/a`! \
MinIO doesn’t permit such a behavior and will throw an error message when attempting to perform such a thing. However, Amazon S3 doesn’t complain at all! That is because Amazon S3 uses a flat namespace to organize its files and directories, while MinIO uses the file system hierarchy for storing (see [this discussion](https://github.com/minio/minio/issues/7335) for more info). With file systems we can not have a file with the same name as a directory at the same place. We had in fact stumbled with this issue when developing the file system backend some time ago, and had to develop a mechanism to allow this behavior and store the values for both events. However on this new S3 backend, a mechanism for this is not implemented for the moment, so you need to keep that into consideration when using this backend alongside MinIO at this stage.

## Sample timestamps

We are not yet taking into consideration the timestamps of the samples, this may cause problems in some edge cases, for instance in the case we send a PUT immediately followed by a DELETE on the same key expression, it may happen that the DELETE operation gets to the storage earlier than the PUT, which would cause a file to be kept stored instead of being removed as intended, due to order issues. Taking the timestamps into account would have allowed us in this example case to discard the PUT operation, avoiding to corrupt the storage. This is yet to be implemented and an [issue](https://github.com/eclipse-zenoh/zenoh-backend-s3/issues/5) is already opened for it.

## Replicas support

Replication is not yet supported from the Zenoh side. If we have two S3 backends subscribed to the same key expression and one goes momentarily down, when respawning it needs to fetch the data it missed from the other backend to synchronize. This is not yet implemented. We can, however, profit from the replication mechanisms both Amazon S3 and MinIO provide.

Another replication problem comes in when we want to have multiple but with different backends, for instance S3 and RocksDB. There is no workaround for this at the moment and it’s up to the user to manually take care of synchronization.

## Aws-sdk-s3 library

Finally, this implementation relies on Amazon’s [aws-sdk-s3 Rust crate](https://crates.io/crates/aws-sdk-s3), which is itself under development and clearly states: “_Please Note: The SDK is currently in Developer Preview and is intended strictly for feedback purposes only. Do not use this SDK for production workloads._” So, you need to take that into strong consideration before making a production release.

As of today, the amazon’s engineering team that’s developing this crate is regularly publishing new versions of it. As a consequence, new versions of this backend are to be expected in the future in order to update the dependency versions.
